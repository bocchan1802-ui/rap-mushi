// ãƒ©ãƒƒãƒ—ãƒ ã—ã‚¯ãƒ­ãƒ¼ãƒ³ - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆé«˜é€ŸåŒ–ç‰ˆï¼‰

class RapMushiApp {
  constructor() {
    // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šï¼ˆkorosukeã®å£°ï¼‰
    this.audioFiles = {
      1: { file: 'audio/phrase1.wav', text: 'ãƒ¨ãƒ¼ã‚·ï¼', buffer: null },
      2: { file: 'audio/phrase2.wav', text: 'ãƒã‚¸ï¼ï¼Ÿ', buffer: null },
      3: { file: 'audio/phrase3.wav', text: 'ã‚¦ã‚±ã‚‹ï¼', buffer: null },
      4: { file: 'audio/phrase4.wav', text: 'ãƒŠã‚¤ã‚¹ï¼', buffer: null },
      5: { file: 'audio/phrase5.wav', text: 'ã‚„ã°ã¿ï¼', buffer: null },
      6: { file: 'audio/phrase6.wav', text: 'ã™ã”ã‰ï¼', buffer: null },
      7: { file: 'audio/phrase7.wav', text: 'ã¸ã‡ã€œ', buffer: null },
      8: { file: 'audio/phrase8.wav', text: 'ã‚ã–ã£ï¼', buffer: null }
    };

    this.isRecording = false;
    this.isPlaying = false;
    this.recordedPhrases = [];
    this.audioContext = null;
    this.analyser = null;
    this.mediaStream = null;
    this.mockMode = false; // éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ãƒ¢ãƒ¼ãƒ‰ï¼ˆkorosukeã®å£°ï¼‰
    this.audioBuffersLoaded = false; // ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†ãƒ•ãƒ©ã‚°
    this.activeSources = []; // å†ç”Ÿä¸­ã®AudioSourceã‚’è¿½è·¡

    this.initElements();
    this.initAudio();
    this.preloadAudio(); // ğŸ‘ˆ éŸ³å£°ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰
    this.bindEvents();
  }

  initElements() {
    this.mushiCharacter = document.querySelector('.mushi-character');
    this.mushiMouth = document.getElementById('mushiMouth');
    this.currentText = document.getElementById('currentText');
    this.rapPads = document.querySelectorAll('.rap-pad');
    this.recordBtn = document.getElementById('recordBtn');
    this.playBtn = document.getElementById('playBtn');
    this.clearBtn = document.getElementById('clearBtn');
    this.historyList = document.getElementById('historyList');
    this.volumeBar = document.getElementById('volumeBar');
    this.helpBtn = document.getElementById('helpBtn');
    this.helpModal = document.getElementById('helpModal');
    this.closeHelp = document.getElementById('closeHelp');
    this.loadingIndicator = document.querySelector('.loading-indicator');
  }

  initAudio() {
    try {
      this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
      this.analyser = this.audioContext.createAnalyser();
      this.analyser.fftSize = 256;
    } catch (e) {
      console.warn('Web Audio API not available');
    }
  }

  // ğŸ‘ˆ éŸ³å£°ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ï¼ˆã‚²ãƒ¼ãƒ é–‹å§‹æ™‚ã«å…¨ã¦ã®éŸ³å£°ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿ï¼‰
  async preloadAudio() {
    if (!this.audioContext) {
      console.warn('AudioContext not available');
      return;
    }

    // AudioContextã®ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œè¦æ±‚ã«å¯¾å‡¦
    if (this.audioContext.state === 'suspended') {
      await this.audioContext.resume();
    }

    console.log('ğŸµ éŸ³å£°ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰é–‹å§‹...');

    const loadPromises = Object.entries(this.audioFiles).map(async ([id, phrase]) => {
      try {
        const response = await fetch(phrase.file);
        if (!response.ok) throw new Error(`Failed to load ${phrase.file}`);

        const arrayBuffer = await response.arrayBuffer();
        const audioBuffer = await this.audioContext.decodeAudioData(arrayBuffer);

        this.audioFiles[id].buffer = audioBuffer;
        console.log(`  âœ… Loaded: ${phrase.file}`);
      } catch (error) {
        console.warn(`  âš ï¸ Failed to load ${phrase.file}:`, error);
      }
    });

    await Promise.all(loadPromises);
    this.audioBuffersLoaded = true;

    console.log('ğŸ‰ éŸ³å£°ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼å…¨ã¦ã®éŸ³å£°ãŒãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ');

    // ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤ºã‚’éè¡¨ç¤º
    if (this.loadingIndicator) {
      this.loadingIndicator.style.display = 'none';
    }

    // ãƒ‘ãƒƒãƒ‰ã‚’æœ‰åŠ¹åŒ–
    this.rapPads.forEach(pad => {
      pad.classList.add('loaded');
      pad.disabled = false;
    });
  }

  async startAudioAnalysis() {
    try {
      this.mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const source = this.audioContext.createMediaStreamSource(this.mediaStream);
      source.connect(this.analyser);

      const dataArray = new Uint8Array(this.analyser.frequencyBinCount);

      const updateVolume = () => {
        if (!this.isRecording) return;

        this.analyser.getByteFrequencyData(dataArray);
        const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
        const volume = (average / 255) * 100;
        this.volumeBar.style.width = volume + '%';

        requestAnimationFrame(updateVolume);
      };

      updateVolume();
    } catch (e) {
      console.warn('Microphone access not available:', e);
    }
  }

  stopAudioAnalysis() {
    if (this.mediaStream) {
      this.mediaStream.getTracks().forEach(track => track.stop());
      this.mediaStream = null;
    }
    this.volumeBar.style.width = '0%';
  }

  bindEvents() {
    // ãƒ©ãƒƒãƒ—ãƒ‘ãƒƒãƒ‰
    this.rapPads.forEach(pad => {
      pad.addEventListener('click', () => {
        const soundId = pad.dataset.sound;
        this.playPhrase(soundId);
      });

      pad.addEventListener('touchstart', (e) => {
        e.preventDefault();
        const soundId = pad.dataset.sound;
        this.playPhrase(soundId);
      });
    });

    // éŒ²éŸ³ãƒœã‚¿ãƒ³
    this.recordBtn.addEventListener('click', () => {
      if (this.isRecording) {
        this.stopRecording();
      } else {
        this.startRecording();
      }
    });

    // å†ç”Ÿãƒœã‚¿ãƒ³
    this.playBtn.addEventListener('click', () => {
      if (this.isPlaying) {
        this.stopPlayback();
      } else {
        this.playRecording();
      }
    });

    // æ¶ˆå»ãƒœã‚¿ãƒ³
    this.clearBtn.addEventListener('click', () => {
      this.clearRecording();
    });

    // ãƒ˜ãƒ«ãƒ—ãƒ¢ãƒ¼ãƒ€ãƒ«
    this.helpBtn.addEventListener('click', () => {
      this.helpModal.classList.add('active');
    });

    this.closeHelp.addEventListener('click', () => {
      this.helpModal.classList.remove('active');
    });

    this.helpModal.addEventListener('click', (e) => {
      if (e.target === this.helpModal) {
        this.helpModal.classList.remove('active');
      }
    });
  }

  playPhrase(soundId) {
    const phrase = this.audioFiles[soundId];
    if (!phrase) return;

    // ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
    this.currentText.textContent = phrase.text;

    // ãƒ‘ãƒƒãƒ‰ã®ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
    const pad = document.querySelector(`[data-sound="${soundId}"]`);
    pad.classList.add('playing');
    setTimeout(() => pad.classList.remove('playing'), 300);

    // è™«ã‚’ãƒ©ãƒƒãƒ—çŠ¶æ…‹ã«
    this.mushiCharacter.classList.add('rapping');

    // ğŸ‘ˆ é«˜é€Ÿå†ç”Ÿï¼šãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸAudioBufferã‚’ä½¿ç”¨
    if (this.mockMode) {
      this.speakMock(phrase.text);
    } else {
      this.playAudioBuffer(soundId);
    }

    // éŒ²éŸ³ä¸­ãªã‚‰å±¥æ­´ã«è¿½åŠ 
    if (this.isRecording) {
      this.recordedPhrases.push({
        id: soundId,
        text: phrase.text,
        time: Date.now()
      });
      this.updateHistory();
    }

    // ä¸€å®šæ™‚é–“å¾Œã«ãƒ©ãƒƒãƒ—çŠ¶æ…‹ã‚’è§£é™¤
    setTimeout(() => {
      this.mushiCharacter.classList.remove('rapping');
    }, 500);
  }

  // ğŸ‘ˆ é«˜é€Ÿå†ç”Ÿï¼šAudioBufferã‚’ä½¿ç”¨ã—ãŸå³åº§å†ç”Ÿ
  playAudioBuffer(soundId) {
    if (!this.audioContext) {
      console.warn('AudioContext not available');
      return;
    }

    const phrase = this.audioFiles[soundId];

    // AudioBufferãŒãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆ
    if (phrase.buffer) {
      const source = this.audioContext.createBufferSource();
      source.buffer = phrase.buffer;
      source.connect(this.audioContext.destination);
      source.start(0);

      // å†ç”Ÿå®Œäº†å¾Œã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      source.onended = () => {
        const index = this.activeSources.indexOf(source);
        if (index > -1) {
          this.activeSources.splice(index, 1);
        }
      };
      this.activeSources.push(source);

      return;
    }

    // ãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    console.warn(`Audio buffer for sound ${soundId} not loaded, using fallback`);
    this.playAudioFile(phrase.file);
  }

  speakMock(text) {
    // Web Speech API for TTSï¼ˆãƒ¢ãƒƒã‚¯ç”¨ï¼‰
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ja-JP';
    utterance.rate = 1.5;
    utterance.pitch = 1.8;

    const voices = speechSynthesis.getVoices();
    const japaneseVoice = voices.find(v => v.lang.includes('ja'));
    if (japaneseVoice) {
      utterance.voice = japaneseVoice;
    }

    speechSynthesis.speak(utterance);
  }

  playAudioFile(filePath) {
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šAudioè¦ç´ ã‚’ä½¿ç”¨
    const audio = new Audio(filePath);
    audio.play().catch(e => {
      console.warn('Audio file not found, falling back to mock:', e);
      this.speakMock(this.audioFiles[this.findIdByFile(filePath)].text);
    });
  }

  findIdByFile(filePath) {
    for (const [id, data] of Object.entries(this.audioFiles)) {
      if (data.file === filePath) return id;
    }
    return null;
  }

  startRecording() {
    this.isRecording = true;
    this.recordBtn.classList.add('recording');
    this.recordBtn.querySelector('.btn-text').textContent = 'éŒ²éŸ³ä¸­...';
    this.startAudioAnalysis();
  }

  stopRecording() {
    this.isRecording = false;
    this.recordBtn.classList.remove('recording');
    this.recordBtn.querySelector('.btn-text').textContent = 'éŒ²éŸ³';
    this.stopAudioAnalysis();

    if (this.recordedPhrases.length > 0) {
      this.playBtn.disabled = false;
    }
  }

  async playRecording() {
    if (this.recordedPhrases.length === 0) return;

    this.isPlaying = true;
    this.playBtn.classList.add('playing');
    this.playBtn.querySelector('.btn-text').textContent = 'å†ç”Ÿä¸­...';

    for (const phrase of this.recordedPhrases) {
      if (!this.isPlaying) break;

      const pad = document.querySelector(`[data-sound="${phrase.id}"]`);
      pad.classList.add('playing');
      setTimeout(() => pad.classList.remove('playing'), 300);

      this.currentText.textContent = phrase.text;
      this.mushiCharacter.classList.add('rapping');

      if (this.mockMode) {
        await this.speakMockAsync(phrase.text);
      } else {
        await this.playAudioBufferAsync(phrase.id);
      }

      await this.delay(100);
      this.mushiCharacter.classList.remove('rapping');
    }

    this.stopPlayback();
  }

  speakMockAsync(text) {
    return new Promise((resolve) => {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ja-JP';
      utterance.rate = 1.5;
      utterance.pitch = 1.8;

      const voices = speechSynthesis.getVoices();
      const japaneseVoice = voices.find(v => v.lang.includes('ja'));
      if (japaneseVoice) {
        utterance.voice = japaneseVoice;
      }

      utterance.onend = resolve;
      speechSynthesis.speak(utterance);
    });
  }

  // ğŸ‘ˆ é«˜é€Ÿå†ç”Ÿï¼šAudioBufferã‚’ä½¿ç”¨ã—ãŸéåŒæœŸå†ç”Ÿ
  async playAudioBufferAsync(soundId) {
    if (!this.audioContext) {
      console.warn('AudioContext not available');
      return;
    }

    const phrase = this.audioFiles[soundId];

    // AudioBufferãŒãƒ—ãƒªãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆ
    if (phrase.buffer) {
      return new Promise((resolve) => {
        const source = this.audioContext.createBufferSource();
        source.buffer = phrase.buffer;
        source.connect(this.audioContext.destination);
        source.start(0);

        source.onended = () => {
          const index = this.activeSources.indexOf(source);
          if (index > -1) {
            this.activeSources.splice(index, 1);
          }
          resolve();
        };
        this.activeSources.push(source);
      });
    }

    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return this.playAudioFileAsync(phrase.file);
  }

  playAudioFileAsync(filePath) {
    return new Promise((resolve) => {
      const audio = new Audio(filePath);
      audio.onended = resolve;
      audio.onerror = () => {
        const id = this.findIdByFile(filePath);
        this.speakMockAsync(this.audioFiles[id].text).then(resolve);
      };
      audio.play();
    });
  }

  stopPlayback() {
    this.isPlaying = false;
    this.playBtn.classList.remove('playing');
    this.playBtn.querySelector('.btn-text').textContent = 'å†ç”Ÿ';

    // å…¨ã¦ã®AudioSourceã‚’åœæ­¢
    this.activeSources.forEach(source => {
      try {
        source.stop();
      } catch (e) {
        // æ—¢ã«åœæ­¢æ¸ˆã¿
      }
    });
    this.activeSources = [];

    speechSynthesis.cancel();
  }

  clearRecording() {
    this.recordedPhrases = [];
    this.updateHistory();
    this.playBtn.disabled = true;
    this.currentText.textContent = 'ã‚¿ãƒƒãƒ—ã—ã¦ãƒ©ãƒƒãƒ—ï¼';
  }

  updateHistory() {
    if (this.recordedPhrases.length === 0) {
      this.historyList.innerHTML = '<p class="empty">ã¾ã ãƒ©ãƒƒãƒ—ã—ã¦ã„ã¾ã›ã‚“...</p>';
      return;
    }

    this.historyList.innerHTML = this.recordedPhrases.map((phrase, index) => `
      <div class="history-item">
        <span class="history-phrase">${index + 1}. ${phrase.text}</span>
        <span class="history-time">${new Date(phrase.time).toLocaleTimeString()}</span>
      </div>
    `).join('');
  }

  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// ã‚¢ãƒ—ãƒªèµ·å‹•
document.addEventListener('DOMContentLoaded', () => {
  new RapMushiApp();
});

// éŸ³å£°ãƒªã‚¹ãƒˆãŒèª­ã¿è¾¼ã¾ã‚ŒãŸã‚‰åˆæœŸåŒ–
speechSynthesis.onvoiceschanged = () => {
  // éŸ³å£°ãƒªã‚¹ãƒˆãŒæ›´æ–°ã•ã‚ŒãŸ
};
